---
layout: layouts/home.njk
---

<div class="max-w-lg mx-4 mt-12 2xl:max-w-screen-xl lg:mx-auto">
  <div class="max-w-screen-md mx-auto">
    <div class="mx-auto bg-[url('/img/zappa.png')] bg-contain w-[80px] h-[80px] bg-no-repeat"></div>
    <h1 class="mt-4 text-5xl font-bold text-center text-gray-200">Initial User Research to counteract misinformation on social networks</h1>
    <div class="flex items-center">
    <time class="badge badge-info text-center mt-5 mx-auto">v0.1 - 4th March 2022</time>
    </div>
    <div class="relative mt-20"> 
        <div class="absolute left-[-150px] top-[-60px]">
            <span class="italic">Watch our mindmap</span>
            <svg class="absolute top-[12px] right-[-80px]" width="74" height="41" viewBox="0 0 74 41" fill="none" xmlns="http://www.w3.org/2000/svg">
                <path d="M73.5 40.9999L73.7311 35.231L68.6195 37.9153L73.5 40.9999ZM0.546961 1.99779C8.89705 1.21005 22.4869 3.05215 36.0149 8.59695C49.5376 14.1396 62.9357 23.3561 70.9734 37.2633L71.8392 36.7629C63.6562 22.6042 50.0467 13.2675 36.3942 7.67166C22.747 2.07799 8.99411 0.196449 0.453039 1.00221L0.546961 1.99779Z" fill="#D4D5D7"/>
            </svg>
        </div>
        <div class="mt-8 relative pb-[57%] h-0">  
        <iframe src="https://www.loom.com/embed/4286507989d749b683ce228d1a3af9f5" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
        </div>
    </div>
  </div>
</div>

<div class="prose mx-auto max-w-[46rem] my-24">
    <h2> Introduction</h2>
    <p>The Zappa project is funded by a grant from the Culture of Solidarity fund to support cross-border cultural initiatives of solidarity in times of uncertainty and "infodemic". 
        The aim of this initial user research was to help guide development of a custom Bonfire extension to empower communities with a dedicated tool to deal with online misinformation.  </p>
    <h2>Methodology</h2>
    <p>For the purposes of this research, we used a simple definition of misinformation as being information which is either incorrect or misleading but which is presented (or re-shared) as fact, Disinformation is on the same spectrum as misinformation, but the intention is to intentionally deceive.</p>
<p>We found a spectrum in the graphic below from First Draft as useful in helping frame the discussion with our user research participants. </p>

<img src="/img/zappa1.png" alt="">

<p>Our user research participants were volunteers who we recruited through our networks - either directly through an existing relationship, a referral from a contact, or a response to a general request sent out via the Fediverse.</p>
<p>We outlined the kinds of people who we wanted to speak with through some initial brainstorming, which was refined after talking to our first couple of user resarch participants. The board below shows who we wanted to talk with and the themes we wanted to cover.</p>

<img src="/img/zappa2.png" alt="">


<p>Over the four-week user research period we conducted 10 user research interviews via video conference and, in addition, had one participant who preferred to answer our questions asynchronously via email.</p>
<p>As the screenshot of our board above demonstrates, we were aiming to talk to a wide range of stakeholders and cover a number of themes. The boxes are prioritised from top to bottom under each grey box, with for example “people who have a practical interest in the area” being given greater priority than “people with a technical interest in the project”.</p>
<p>The green boxes indicate those groups or themes we believe that we covered during the user research process, with those in yellow being those we do not believe we fully covered. </p>

<h2>Findings</h2>
<p>Our research opened our eyes to important work being done by individuals and organisations, primarily in Europe and North America. Two user research participants also discussed work being done in South America, and one mentioned a project with an organisation based in Asia.</p>
<p>The mindmap below shows some of the most relevant findings from our research, detailing problems around misinformation, who is affected by it, as well as what works, what might work, and what doesn’t work. We were particularly grateful for one user research participant suggesting a categorisation based on technical, relational, and procedural solutions, which they are using in their work.</p>

<img src="/img/zappa3.png" alt="">


<p>Broadly speaking, our main findings were that:</p>
<ul>
    <li><b>Blocking</b> - there is a broad assumption among users that technical solutions such as blocking problematic accounts is an effective solution. However, those who have thought about this more deeply recognise that this approach misses the bigger picture, deals with symptoms rather than causes, and simply pushes the problem elsewhere. That being said, blocking and/or muting individual user accounts and instances is still an important tool in dealing with misinformation. Having tools which go beyond a simple binary block/unblock would help users manage this process.</li>
    <li><b>Verification</b>  - the advent of verified accounts is problematic when it comes to misinformation as even verified accounts can publish misinformation. As a result, verification should happen on the level of individual posts rather than accounts.</li>
    <li><b>Labelling</b>  - rating systems and fact-checking can be extremely time-consuming. It can also lead to unintended consequences such as drawing attention to the misinformation. A more promising approach is to label persistent sources of misinformation so that users are warned and can make up their own mind.</li>
    <li><b>Algorithms</b>  - there are many ways to apply AI, machine learning, and algorithms to social networks. Centralised, proprietary, for-profit social networks such as Twitter and Instagram use closed algorithms to curate information on behalf of users. These can amplify problematic content for the sake of engagement (and related advertising dollars). Instead, a “personal AI” or algorithm which is open to be changed by users and to help them could be a promising idea to pursue.</li>
    <li><b>Moderation</b>  - there will always be a need for moderators within social networks, to enforce community standards, to resolve disputes, and to deal with misinformation. The visibility of moderation is a balance between burdening users with additional information and keeping them informed about decisions being made on their behalf. Layering information so that users can go deeper should they wish is a potential avenue to explore through UX design.</li>
    <p>In addition, we discovered that:</p>
    <li><b>Bots</b>  - people feel different (less hesitant) in blocking non-human user accounts, for example if they are ‘sock puppet’ accounts from bad actors.</li>
    <li><b>Consequences</b> - poor behaviour online is often tied to a lack of consequences for a user’s actions, for example in sharing misinformation or trolling.</li>
    <li><b>Governance</b>  - creating social spaces is much easier than thinking about the governance it takes to make them safe spaces and/or ensure their sustainability.</li>
    <li><b>Literacy</b>  - there has not only been an erosion of media literacy through ‘frictionless design’ and an intention not to make users think, but ‘context collapse’ overwhelms users who have neither the conceptual tools nor technical skills to cope.</li>
    <li><b>Censorship</b>  - this is not only a problem of not giving particular users access to networks or resources, but also of causing resources to disappear. This has a knock-on effect of some users (e.g. journalists) being distrusted when the information on which they rely no longer exists.</li>
</ul>
<h2>Reccomendations</h2>
<p>Based on this initial user research, we recommend these initial actions:</p>
<h2>A) Use a multi-pronged approach</h2>
As one user research participant mentioned explicitly, and several alluded to, there is no way to ‘solve’ or ‘fix’ misinformation - either online or offline. Consequently, approaching the problem holistically with a range of interventions is likely to work best. 
These interventions may cover ‘technical’, ‘reputational’ and ‘process-based’  approaches, and include:
<ul>
    <li><b>Automatic labelling</b> of problematic third-party sources of information based on a list curated by instance admins/moderators. Reddit, for example, already does this with The Daily Mail, a UK news outlet.</li>
    <li><b>Opt-in blocklists</b> to which users can subscribe. From a technical point of view, these may actually be ‘flaglists’ or ‘mutelists’, and save end users from some of the burden of manual curation.</li>
    <li><b>UX design</b> that allows users to reveal information on-demand, rather than by default. For example, users may be able to see a source or post is contested without being presented with all of the details by default.</li> 
</ul>

<h2>B) Ensure bot accounts are clearly identifed</h2>
<p>Users interact with bots differently than with accounts they know to have humans behind them. By ensuring that bot accounts are labelled as such users are free to make informed decisions about the range of actions they have such as unfollowing, muting, blocking, and reporting.</p>

<h2>C) Experimenting with user-controlled machine learning</h2>
<p>The notion of a ‘personal AI’ is a powerful one and could be based on a number of variables. This could include the personal AI, for example suggesting:</p>
<ul>
    <li><b>Source/outlet</b> - third-party outlets that users may: 
<ul><li>be interested in based on their network’s activity</li>
<li>not want to see links to in their feeds due to their network’s blocking/muting/flagging behaviour</li></ul></li>
    <li><b>Keywords</b> - words and hashtags that users may: 
<ul><li>be interested in based on their network’s activity</li>
<li>wish to hide, either temporarily or permanently, based on their network’s behaviour</li></ul></li>
    <li><b>Accounts</b> - user accounts that users may:
<ul><li>wish to follow based on their network’s follows</li>
<li>wish to mute, rate-limit, or block based on their network’s blocking/muting/flagging behaviour</li></ul></li>
<p>This could be extended to other metadata available to the system, such as preferring some instances over others, interacting with user accounts or timelines differently at different times of the day, or visualising a user’s social graph.</p>
<h2>D) Carry out more user research with under-represented groups</h2>
<p>This initial user research was skewed towards white, male participants between the ages of 25 and 50, with two exceptions. In addition, we did not manage to talk with existing administrators or moderators of Fediverse instances, nor with anyone currently residing in Asia or Africa.</p>
<p>We therefore acknowledge and regret the limitations of the data obtained from this initial user research and suggest that further research and/org testing take place in the next few months. In particular, this should focus on people who do not identify as white, male, and people who live in the Global South.</p>
<h2>E) Carry out desk research to follow-up promising leads</h2>
<p>A number of websites, initiatives, and individuals were mentioned by user research participants. Two days of desk research would enable these to be collated and other, related projects mapped and contacted. </p>

<h2>Next steps</h2>
<p>After feedback on this report from the Bonfire team, the next steps are to:
<ul><li>Create a Venn diagram showing overlap between technical, relational, and procedural approaches  </li>
<li>Brainstorm some potential interventions based on the Venn diagram</li>
<li>Redraft report based on further research</li></ul></p>

<h2>References / thanks</h2>
<p>We’d like to thank our individual user research participants: anubis2814, Benedict, Kevin, Mariha, Phevos, and Victor. In addition, our thanks to representatives from The New Design Congress, Niboe, Simply Secure, and WITNESS.</p>
</div>
{# <div class="p-16 mt-20 bg-base-content bg-opacity-10">
    <div class="text-3xl font-bold text-center text-base-content">Project sponsors</div>
    <div class="flex items-center max-w-screen-lg mx-auto mt-8 space-x-4 place-content-center">
        <div class="bg-contain  bg-no-repeat w-40 bg-[url('/img/ecf2.png')] h-20"></div>
        <a href="https://opencollective.com/bonfire-networks/contribute" class="normal-case btn btn-outline">Become a sponsor</a>
    </div>
</div> #}

{# <div class="py-12 bg-base-100">
<div class="max-w-screen-md mx-4 my-12 2xl:max-w-screen-xl lg:mx-auto">
    <div class="text-2xl font-bold text-center text-base-content">How can Bonfire and Zappa promote a better and safer social networking experience ?</div>
    <div class="grid grid-cols-1 gap-24 mt-12 md:grid-cols-2">
        <div class="col-span-1">
            <div class="flex items-center w-24 h-24 mx-auto rounded-full place-content-center bg-base-content bg-opacity-30">
              <svg xmlns="http://www.w3.org/2000/svg" class="w-8 h-8" viewBox="0 0 20 20" fill="currentColor">
                <path d="M2 4a1 1 0 011-1h2a1 1 0 011 1v12a1 1 0 01-1 1H2a1 1 0 01-1-1V4zM8 4a1 1 0 011-1h2a1 1 0 011 1v12a1 1 0 01-1 1H9a1 1 0 01-1-1V4zM15 3a1 1 0 00-1 1v12a1 1 0 001 1h2a1 1 0 001-1V4a1 1 0 00-1-1h-2z" />
              </svg>
            </div>
            <div class="mt-3 text-lg font-bold text-center text-gray-200">Flexible audiences & granular permissions </div>
            <div class="mt-2 text-base text-center text-base-content">
                Users are able to define who can discover, read or interact with them and their content/activities with a granular set of permissions (known as boundaries in bonfire).
            </div>
             <a href="https://github.com/bonfire-networks/bonfire-app/milestone/16" target="_blank" class="flex items-center gap-2 mt-3 link link-hover place-content-center">
                <span class="text-xs font-medium uppercase text-neutral-content">View milestone</span>
                <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-primary" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                <path stroke-linecap="round" stroke-linejoin="round" d="M17 8l4 4m0 0l-4 4m4-4H2" />
                </svg>
            </a>
        </div>
        <div class="col-span-1">
            <div class="flex items-center w-24 h-24 mx-auto rounded-full place-content-center bg-base-content bg-opacity-30">
                <svg xmlns="http://www.w3.org/2000/svg" class="w-8 h-8" viewBox="0 0 20 20" fill="currentColor">
                <path d="M10 12a2 2 0 100-4 2 2 0 000 4z" />
                <path fill-rule="evenodd" d="M.458 10C1.732 5.943 5.522 3 10 3s8.268 2.943 9.542 7c-1.274 4.057-5.064 7-9.542 7S1.732 14.057.458 10zM14 10a4 4 0 11-8 0 4 4 0 018 0z" clip-rule="evenodd" />
                </svg>
            </div>
            <div class="mt-3 text-lg font-bold text-center text-gray-200">Opt-in moderation lists for blocked and verified content</div>
            <div class="mt-2 text-base text-center text-base-content">
                Users can create or subscribe to opt-in moderation lists, and - according to permissions - contribute to them. Such opt-in lists may include flagged and blocked content, as well as trusted and verified content.
            </div>
            <a href="https://github.com/bonfire-networks/bonfire-app/milestone/28" target="_blank" class="flex items-center gap-2 mt-3 link link-hover place-content-center">
                <span class="text-xs font-medium uppercase text-neutral-content">View milestone</span>
                <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-primary" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                <path stroke-linecap="round" stroke-linejoin="round" d="M17 8l4 4m0 0l-4 4m4-4H2" />
                </svg>
            </a>
        </div>
        <div class="col-span-1">
            <div class="flex items-center w-24 h-24 mx-auto rounded-full place-content-center bg-base-content bg-opacity-30">
                <svg xmlns="http://www.w3.org/2000/svg" class="w-8 h-8" viewBox="0 0 20 20" fill="currentColor">
                <path fill-rule="evenodd" d="M5 9V7a5 5 0 0110 0v2a2 2 0 012 2v5a2 2 0 01-2 2H5a2 2 0 01-2-2v-5a2 2 0 012-2zm8-2v2H7V7a3 3 0 016 0z" clip-rule="evenodd" />
                </svg>
            </div>
            <div class="mt-3 text-lg font-bold text-center text-gray-200">Roles & moderation</div>
            <div class="mt-2 text-base text-center text-base-content">
                The community can decide to decentralise power and responsibility from admins by adding more custom roles to efficiently manage moderation and resolve conflicts.
            </div>
            <a href="https://github.com/bonfire-networks/bonfire-app/milestone/27" target="_blank" class="flex items-center gap-2 mt-3 link link-hover place-content-center">
                <span class="text-xs font-medium uppercase text-neutral-content">View milestone</span>
                <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-primary" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                <path stroke-linecap="round" stroke-linejoin="round" d="M17 8l4 4m0 0l-4 4m4-4H2" />
                </svg>
            </a>
        </div>
        <div class="col-span-1">
            <div class="flex items-center w-24 h-24 mx-auto rounded-full place-content-center bg-base-content bg-opacity-30">
                <svg xmlns="http://www.w3.org/2000/svg" class="w-8 h-8" viewBox="0 0 20 20" fill="currentColor">
                <path d="M13 6a3 3 0 11-6 0 3 3 0 016 0zM18 8a2 2 0 11-4 0 2 2 0 014 0zM14 15a4 4 0 00-8 0v3h8v-3zM6 8a2 2 0 11-4 0 2 2 0 014 0zM16 18v-3a5.972 5.972 0 00-.75-2.906A3.005 3.005 0 0119 15v3h-3zM4.75 12.094A5.973 5.973 0 004 15v3H1v-3a3 3 0 013.75-2.906z" />
                </svg>
            </div>
            <div class="mt-3 text-lg font-bold text-center text-gray-200">Manual and automatic labelling</div>
            <div class="mt-2 text-base text-center text-base-content">
                Users, moderation list editors, or instance moderators can add labels to content, either by hand or by creating filters for auto-labelling. Labels are shown in feeds to aid with quickly identifying certain aspects of information or misinformation.
            </div>
            <a href="https://github.com/bonfire-networks/bonfire-app/milestone/26" target="_blank" class="flex items-center gap-2 mt-3 link link-hover place-content-center">
                <span class="text-xs font-medium uppercase text-neutral-content">View milestone</span>
                <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-primary" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                <path stroke-linecap="round" stroke-linejoin="round" d="M17 8l4 4m0 0l-4 4m4-4H2" />
                </svg>
            </a>
        </div>
        
    </div>
</div>
</div> #}

{# <div class="max-w-screen-lg mx-4 my-12 2xl:max-w-screen-xl lg:mx-auto">
    <h1 class="text-3xl font-bold text-left text-base-content">Blog posts about <span class="underline decoration-wavy decoration-amber-400 underline-offset-8">Zappa:</h1> #}
    {# {% set taglist = collections[ "zappa" ] %}
    {% for post in taglist | reverse %}
    <article class="my-16 lg:my-8 lg:flex lg:space-x-6">
      <div class="w-full h-40 bg-center bg-no-repeat bg-cover rounded shadow-xl lg:w-32 lg:h-32 bg-blueGray-400" style="background-image: url({{ post.data.image }})"></div>
      <div class="flex-1 mt-4 lg:mt-0">
        <h2 class="mb-2 text-2xl font-bold text-blueGray-200 hover:text-blueGray-200 hover:underline">
            <a href="{{ post.url | url }}">
                {% if post.data.title %}
                    {{ post.data.title }}
                {% else %}
                    Untitled
                {% endif %}
            </a>
        </h2>
        <div class="flex items-center space-x-2">
            <span class="flex items-center space-x-1">
                <svg xmlns="http://www.w3.org/2000/svg" class="w-4 h-4 text-base-content text-opacity-70" viewBox="0 0 20 20" fill="currentColor">
                    <path fill-rule="evenodd" d="M6 2a1 1 0 00-1 1v1H4a2 2 0 00-2 2v10a2 2 0 002 2h12a2 2 0 002-2V6a2 2 0 00-2-2h-1V3a1 1 0 10-2 0v1H7V3a1 1 0 00-1-1zm0 5a1 1 0 000 2h8a1 1 0 100-2H6z" clip-rule="evenodd" />
                  </svg>
              <time class="text-xs text-base-content text-opacity-70">{{ post.date | readableDate }}</time>
            </span>
        </div>
        
        
        {% if post.data.description %}
            <p class="my-2 text-sm text-base-content text-opacity-80">
                {{ post.data.description }}
            </p>
        {% endif %}
        <div class="my-2">
            {%- for tag in post.data.tags -%}
            {%- set tagUrl %}/tags/{{ tag | slug }}/{% endset -%}
                <a href="{{ tagUrl | url }}">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-indigo-100 text-indigo-800">
                <svg class="-ml-0.5 mr-1.5 h-2 w-2 text-indigo-400" fill="currentColor" viewBox="0 0 8 8">
                    <circle cx="4" cy="4" r="3" />
                </svg>
                {{ tag }}
                </span>
                </a>
            {%- endfor %}
        </div>
        <div>
            <a href="{{ post.url | url }}" class="text-sm font-bold text-pink-400">
                Read more →
            </a>
        </div>
      </div>
    </article>
  {% endfor %} #}

  {# </div> #}

{% include "support_footer.njk" %}